---
layout: post
title: "基于机器学习的Spark调参方法"
comments: true
date: 2017-10-11
description: "分类器调参"
tag: Spark-paper

---

# Novel Method for Tuning Configuration Parameters of Spark Based on Machine Learning
本文是一篇关于Spark调参的文章，主要方法是基于二分类及多分类器的机器学习方法来对Spark特定job进行参数调整，从而提升作业整体性能。

本篇博文参考自：
>  2016 IEEE 18th International Conference on High Performance Computing and Communications：
> 《Novel Method for Tuning Configuration Parameters of Spark Based on Machine Learning》

---
## 1  文章概述及问题描述
Spark适用范围越来越广，相应的出现一些较为棘手的问题，其中就有job性能提升的问题。通常情况下，都是靠人为经验去调整job参数，以尽量提升job运行性能。但是Spark的参数空间多大180种，单纯靠认为去调整是极其不可靠而且费时的。
因此，本文就spark调参问题，提出一种基于二分类和多分类的机器学习的调参方法。最终发现C5.0算法具有最好的预测效果以及算法执行效率。调参带来的性能提升与默认参数相比，平均达到36%。
整个流程可参考下图：
![](http://ieeexplore.ieee.org/mediastore/IEEE/content/media/7819725/7828341/7828429/7828429-fig-2-large.gif)

---
**那么问题来了，训练数据怎么来的？**
对于某一类spark app，基本上其中的业务类型或是整个应用程序不会发生很大变化，唯一经常发生变动的是其输入数据量，本文的模型考虑到这一方面，将输入数据量作为了模型参数之一。整个训练数据来自于现有spark app的运行日志，在日志中去提取到所需的时间数据和数据量变化的额数据。

---

## 2  相关研究及文中术语
1. **cost-based model**
在Hadoop平台，一些研究成果是基于cost-based model。例如Starfish（前一篇博客有提到过）
但是对于spark来讲，cost-based model并不适合对spark进行建模，因为cost-based是白盒模型，需要我们了解很底层的知识才行，不利于我们模型的构建和迁移；此外，spark中中的很多组件都向用户提供自定义接口，例如调度和shuffle，因此cost-based model不能适用于这些情况。

---
2. **black box models**
黑盒模型对比于白盒，黑盒模型不需要我们了解系统内部原理，而是根据特定负载下job性能的观测值就可以使模型进行运转；除此之外，黑盒模型很灵活，易于匹配到各种环境下的集群。

---

## 3  方法概述

> 文中用于衡量性能的唯一指标是：job execution time的准确率
> 用于评测模型性能的指标为建立模型时间+模型进行预测的时间的综合评估

因为以运行时间为指标去衡量性能的提升，那么问题就转化为在给定参数集的情况下，要预测其job运行时间来与默认参数下的作业时间进行对比。而精确预测时间并不是很有必要，因为只需要关注性能是否有提升即可。
因此，可分为两步来进行：
1）首先用二分类来打标签，如果有提升，label=1，否则lable=0.
2）再用多分类方法将label=1的进行细分，例如将其提升分为25% 20% 15% 10% 5%几个类别，相当于奖训练数据进行切分，多分类模型可以对其进行训练

---


## 4  参数集
调参对象本文选取了主要的18项参数，这些参数列表如下所示，选择这些参数的原因是列表中参数一方面会影响集群性能的消耗，如CPU，mem等，另一方面会影响到spark的调度，shuffle阶段等，最后就是这些参数会随着节点规模、机器配置的变化发生较大变化！
![](/images/posts/sparkMLPara/para.png)

---
   
## 5  数据收集
文中使用了基准测试工具：BigDataBench来构建模型，选择的用例包括sort、wordcout、Grep、NavieBayes。

首先在参数空间上进行抽样，每一种app生成500个参数列表，以供测试使用，并且每种参数表重复测试3次。但是其中最大的问题就是在收集训练数据的过程中，哪个参数的参数值是需要继续向下深入探索的，由于参数空间庞大，此时选择了稀疏采样。特别是详尽的去搜索不同参数子集的空间（也就是去探索一下参数的范围值），以及在收集数据时，均匀地在不同参数值范围内进行随机采样。
以上提到的两种随机采样的方法均有优势：
前一种方法是在我们领域知识的指引下来选择参数值，后一种方法为我们提供一个无偏见的性能观测，这两种方法的结合能够比单独的方法提供更多的实际性能的见解。

---

## 6  模型选择
文中探索了以下几种学习模型：**（以下模型均来自IBM SPSS Modeler）**
1）C5.0
> C5.0是决策树的一种实现，可用于分类和回归，由IBM提出。

2）LR
> 逻辑回归是一种分类模型，模型用于判断类别属性和变量间的关系。

3）SVM
> 支持向量机是一种监督学习模型，用于分类和回归问题，不仅可以用于线性分类，而且也可以解决非线性分类问题

4）ANN
> 人工神经网络基于结构和生物神经网络的计算式模型。可用于非线性数据并能用于分析复杂输入数据内部的关系。ANN是一种很强劲的分类和非线性回归模型，并且适用于多输入输出的情况。


---

## 7 模型训练及验证
为了让模型更好地进行拟合，使用了交叉验证的方法去提升模型的健壮性。
原始数据被随机分为不同的比例用于训练和验证，这样的训练+验证的周期重复进行5次，最后得到平均性能参数。同样这样的流程是由IBM SPSS Modeler和Weka toolkit来作为支撑。

---


## 8 参数空间搜索
在得到最终模型之后，我们要给一组最优参数去得到预测时间，但是这组参数如何搜索仍然是个问题，因为参数空间太大，这里选取Recursive Random Search (RRS)递归随机搜索算法去搜寻参数空间。
步骤：
RSS进行子空间的随机搜索，识别具有较高概率的最优参数集合的范围区域，然后对这些区域中的参数进行递归采样，并且在这些参数区域进行不断移动和逐渐缩小到局部最有参数值，最后重新进行随机采样去寻找更优秀的区域来重复递归搜索。
RSS算法可以提供寻找到最优参数集合的概率保证。



---

**我的简书: <http://www.jianshu.com/p/0090ca6a1bd9>**

*转载请注明原址，谢谢*。
